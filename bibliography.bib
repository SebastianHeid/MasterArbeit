% Large Language Models
@inproceedings{tan2025ominicontrol,
	title={Ominicontrol: Minimal and universal control for diffusion transformer},
	author={Tan, Zhenxiong and Liu, Songhua and Yang, Xingyi and Xue, Qiaochu and Wang, Xinchao},
	booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages={14940--14950},
	year={2025}
}
@article{CFG,
	title={Classifier-free diffusion guidance},
	author={Ho, Jonathan and Salimans, Tim},
	journal={arXiv preprint arXiv:2207.12598},
	year={2022}
}
@article{CG,
	title={Diffusion models beat gans on image synthesis},
	author={Dhariwal, Prafulla and Nichol, Alexander},
	journal={Advances in neural information processing systems},
	volume={34},
	pages={8780--8794},
	year={2021}
}
@article{MMD1,
	title={A kernel method for the two-sample-problem},
	author={Gretton, Arthur and Borgwardt, Karsten and Rasch, Malte and Sch{\"o}lkopf, Bernhard and Smola, Alex},
	journal={Advances in neural information processing systems},
	volume={19},
	year={2006}
}
@article{T5XXL,
	title={Exploring the limits of transfer learning with a unified text-to-text transformer},
	author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
	journal={Journal of machine learning research},
	volume={21},
	number={140},
	pages={1--67},
	year={2020}
}

@article{yu2022scaling,
	title={Scaling autoregressive models for content-rich text-to-image generation},
	author={Yu, Jiahui and Xu, Yuanzhong and Koh, Jing Yu and Luong, Thang and Baid, Gunjan and Wang, Zirui and Vasudevan, Vijay and Ku, Alexander and Yang, Yinfei and Ayan, Burcu Karagol and others},
	journal={arXiv preprint arXiv:2206.10789},
	volume={2},
	number={3},
	pages={5},
	year={2022}
}

@inproceedings{TinyFusion,
	title={Tinyfusion: Diffusion transformers learned shallow},
	author={Fang, Gongfan and Li, Kunjun and Ma, Xinyin and Wang, Xinchao},
	booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},
	pages={18144--18154},
	year={2025}
}

@article{MNIST,
	title={Gradient-based learning applied to document recognition},
	author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
	journal={Proceedings of the IEEE},
	volume={86},
	number={11},
	pages={2278--2324},
	year={2002},
	publisher={Ieee}
}

@article{men2024shortgpt,
	title={Shortgpt: Layers in large language models are more redundant than you expect, 2024},
	author={Men, Xin and Xu, Mingyu and Zhang, Qingyu and Wang, Bingning and Lin, Hongyu and Lu, Yaojie and Han, Xianpei and Chen, Weipeng},
	journal={URL https://arxiv. org/abs/2403.03853},
	volume={2},
	number={3},
	pages={4},
	year={2024}
}

@misc{li2024playground,
	title={Playground v2.5: Three Insights towards Enhancing Aesthetic Quality in Text-to-Image Generation}, 
	author={Daiqing Li and Aleks Kamko and Ehsan Akhgari and Ali Sabet and Linmiao Xu and Suhail Doshi},
	year={2024},
	eprint={2402.17245},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@article{SVD_LLM_V2,
	title={Svd-llm v2: Optimizing singular value truncation for large language model compression},
	author={Wang, Xin and Alam, Samiul and Wan, Zhongwei and Shen, Hui and Zhang, Mi},
	journal={arXiv preprint arXiv:2503.12340},
	year={2025}
}

@article{brooks2024video,
	title={Video generation models as world simulators},
	author={Brooks, Tim and Peebles, Bill and Holmes, Connor and DePue, Will and Guo, Yufei and Jing, Leo and Schnurr, David and Taylor, Joe and Luhman, Troy and Luhman, Eric and others},
	journal={OpenAI Blog},
	volume={1},
	number={8},
	pages={1},
	year={2024}
}

@inproceedings{DLowRankEst,
	title={Dynamic Low-Rank Estimation for Transformer-based Language Models},
	author={Hua, Ting and Li, Xiao and Gao, Shangqian and Hsu, Yen-Chang and Shen, Yilin and Jin, Hongxia},
	booktitle={Findings of the Association for Computational Linguistics: EMNLP 2023},
	pages={9275--9287},
	year={2023}
}

@article{he2023efficientdm,
	title={Efficientdm: Efficient quantization-aware fine-tuning of low-bit diffusion models},
	author={He, Yefei and Liu, Jing and Wu, Weijia and Zhou, Hong and Zhuang, Bohan},
	journal={arXiv preprint arXiv:2310.03270},
	year={2023}
}

@article{esser2019learned,
	title={Learned step size quantization},
	author={Esser, Steven K and McKinstry, Jeffrey L and Bablani, Deepika and Appuswamy, Rathinakumar and Modha, Dharmendra S},
	journal={arXiv preprint arXiv:1902.08153},
	year={2019}
}

@article{bengio2013estimating,
	title={Estimating or propagating gradients through stochastic neurons for conditional computation},
	author={Bengio, Yoshua and L{\'e}onard, Nicholas and Courville, Aaron},
	journal={arXiv preprint arXiv:1308.3432},
	year={2013}
}

@article{tang2023lightweight,
	title={Lightweight diffusion models with distillation-based block neural architecture search},
	author={Tang, Siao and Wang, Xin and Chen, Hong and Guan, Chaoyu and Tang, Yansong and others},
	journal={arXiv preprint arXiv:2311.04950},
	year={2023}
}

@article{yuan2023asvd,
	title={{ASVD}: Activation-aware Singular Value Decomposition for Compressing Large Language Models},
	author={Yuan, Zhihang and Shang, Yuzhang and Song, Yue and Yang, Dawei and Wu, Qiang and Yan, Yan and Sun, Guangyu},
	journal={arXiv preprint arXiv:2312.05821},
	year={2023}
}

@inproceedings{GRASP,
	title={{GRASP}: Replace Redundant Layers with Adaptive Singular Parameters for Efficient Model Compression},
	author={Liu, Kainan and Zhang, Yong and Cheng, Ning and Li, Zhitao and Wang, Shaojun and Xiao, Jing},
	booktitle={Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing},
	pages={26344--26359},
	year={2025}
}


@inproceedings{wang2025svd,
	title={{SVD-LLM} v2: Optimizing Singular Value Truncation for Large Language Model Compression},
	author={Wang, Xin and Alam, Samiul and Wan, Zhongwei and Shen, Hui and Zhang, Mi},
	booktitle={Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
	pages={4287--4296},
	year={2025}
}

@article{han2015deep,
	title={Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding},
	author={Han, Song and Mao, Huizi and Dally, William J.}, 
	journal={arXiv preprint arXiv:1510.00149},
	year={2015}
}

@misc{lefaudeux2022xformers,
	author = {Lefaudeux, B. and Massa, F. and Liskovich, D. and Xiong, W. and Caggiano, V. and Naren, S. and Xu, M. and Hu, J. and Tintore, M. and Zhang, S. and Labatut, P. and Haziza, D. and Wehrstedt, L. and Reizenstein, J. and Sizov, G.},
	title = {xFormers: A Modular and Hackable Transformer Modelling Library},
	howpublished = {\url{https://github.com/facebookresearch/xformers}},
	year = {2022}
}

@article{BF16,
	title={A study of BFLOAT16 for deep learning training},
	author={Kalamkar, Dhiraj and Mudigere, Dheevatsa and Mellempudi, Naveen and Das, Dipankar and Banerjee, Kunal and Avancha, Sasikanth and Vooturi, Dharma Teja and Jammalamadaka, Nataraj and Huang, Jianyu and Yuen, Hector and others},
	journal={arXiv preprint arXiv:1905.12322},
	year={2019}
}

@article{li2024svdquant,
	title={Svdquant: Absorbing outliers by low-rank components for 4-bit diffusion models},
	author={Li, Muyang and Lin, Yujun and Zhang, Zhekai and Cai, Tianle and Li, Xiuyu and Guo, Junxian and Xie, Enze and Meng, Chenlin and Zhu, Jun-Yan and Han, Song},
	journal={arXiv preprint arXiv:2411.05007},
	year={2024}
}

@inproceedings{nagel2020up,
	title={Up or down? adaptive rounding for post-training quantization},
	author={Nagel, Markus and Amjad, Rana Ali and Van Baalen, Mart and Louizos, Christos and Blankevoort, Tijmen},
	booktitle={International conference on machine learning},
	pages={7197--7206},
	year={2020},
	organization={PMLR}
}

@article{so2023temporal,
	title={Temporal dynamic quantization for diffusion models},
	author={So, Junhyuk and Lee, Jungwon and Ahn, Daehyun and Kim, Hyungjun and Park, Eunhyeok},
	journal={Advances in neural information processing systems},
	volume={36},
	pages={48686--48698},
	year={2023}
}

@article{he2023ptqd,
	title={Ptqd: Accurate post-training quantization for diffusion models},
	author={He, Yefei and Liu, Luping and Liu, Jing and Wu, Weijia and Zhou, Hong and Zhuang, Bohan},
	journal={Advances in Neural Information Processing Systems},
	volume={36},
	pages={13237--13249},
	year={2023}
}

@inproceedings{jacob2018quantization,
	title={Quantization and training of neural networks for efficient integer-arithmetic-only inference},
	author={Jacob, Benoit and Kligys, Skirmantas and Chen, Bo and Zhu, Menglong and Tang, Matthew and Howard, Andrew and Adam, Hartwig and Kalenichenko, Dmitry},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={2704--2713},
	year={2018}
}

@inproceedings{cai2020zeroq,
	title={Zeroq: A novel zero shot quantization framework},
	author={Cai, Yaohui and Yao, Zhewei and Dong, Zhen and Gholami, Amir and Mahoney, Michael W and Keutzer, Kurt},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages={13169--13178},
	year={2020}
}

@inproceedings{QDiT,
	title={Q-dit: Accurate post-training quantization for diffusion transformers},
	author={Chen, Lei and Meng, Yuan and Tang, Chen and Ma, Xinzhu and Jiang, Jingyan and Wang, Xin and Wang, Zhi and Zhu, Wenwu},
	booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},
	pages={28306--28315},
	year={2025}
}

@inproceedings{QDiffusion,
	title={Q-diffusion: Quantizing diffusion models},
	author={Li, Xiuyu and Liu, Yijiang and Lian, Long and Yang, Huanrui and Dong, Zhen and Kang, Daniel and Zhang, Shanghang and Keutzer, Kurt},
	booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages={17535--17545},
	year={2023}
}

@article{PTQD,
	title={Ptqd: Accurate post-training quantization for diffusion models},
	author={He, Yefei and Liu, Luping and Liu, Jing and Wu, Weijia and Zhou, Hong and Zhuang, Bohan},
	journal={Advances in Neural Information Processing Systems},
	volume={36},
	pages={13237--13249},
	year={2023}
}

@article{li2023snapfusion,
	title={Snapfusion: Text-to-image diffusion model on mobile devices within two seconds},
	author={Li, Yanyu and Wang, Huan and Jin, Qing and Hu, Ju and Chemerys, Pavlo and Fu, Yun and Wang, Yanzhi and Tulyakov, Sergey and Ren, Jian},
	journal={Advances in Neural Information Processing Systems},
	volume={36},
	pages={20662--20678},
	year={2023}
}

@inproceedings{chen2023speed,
	title={Speed is all you need: On-device acceleration of large diffusion models via gpu-aware optimizations},
	author={Chen, Yu-Hui and Sarokin, Raman and Lee, Juhyun and Tang, Jiuqiang and Chang, Chuo-Ling and Kulik, Andrei and Grundmann, Matthias},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={4651--4655},
	year={2023}
}

@article{han2015deep,
	title={Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding},
	author={Han, Song and Mao, Huizi and Dally, William J},
	journal={arXiv preprint arXiv:1510.00149},
	year={2015}
}

@article{PPCL,
	title={Pluggable Pruning with Contiguous Layer Distillation for Diffusion Transformers},
	author={Ma, Jian and Peng, Qirong and Zhu, Xujie and Xie, Peixing and Chen, Chen and Lu, Haonan},
	journal={arXiv preprint arXiv:2511.16156},
	year={2025}
}

@article{HierarchicalPrune,
	title={HierarchicalPrune: Position-Aware Compression for Large-Scale Diffusion Models},
	author={Kwon, Young D and Li, Rui and Li, Sijia and Li, Da and Bhattacharya, Sourav and Venieris, Stylianos I},
	journal={arXiv preprint arXiv:2508.04663},
	year={2025}
}

@article{EcoDiff,
	title={Learnable Sparsity for Vision Generative Models},
	author={Zhang, Yang and Jin, Er and Liang, Wenzhong and Dong, Yanfei and Khakzar, Ashkan and Torr, Philip and Stegmaier, Johannes and Kawaguchi, Kenji},
	journal={arXiv preprint arXiv:2412.02852},
	year={2024}
}

@article{FluxBit,
	title={1.58-bit FLUX},
	author={Yang, Chenglin and Liu, Celong and Deng, Xueqing and Kim, Dongwon and Mei, Xing and Shen, Xiaohui and Chen, Liang-Chieh},
	journal={arXiv preprint arXiv:2412.18653},
	year={2024}
}

@inproceedings{zhao2024mobilediffusion,
	title={Mobilediffusion: Instant text-to-image generation on mobile devices},
	author={Zhao, Yang and Xu, Yanwu and Xiao, Zhisheng and Jia, Haolin and Hou, Tingbo},
	booktitle={European Conference on Computer Vision},
	pages={225--242},
	year={2024},
	organization={Springer}
}

@misc{ruiz2023dreamboothfinetuningtexttoimage,
	title={DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation}, 
	author={Nataniel Ruiz and Yuanzhen Li and Varun Jampani and Yael Pritch and Michael Rubinstein and Kfir Aberman},
	year={2023},
	eprint={2208.12242},
	archivePrefix={arXiv},
	primaryClass={cs.CV},
	url={https://arxiv.org/abs/2208.12242}, 
}
@article{baldridge2024imagen,
	title={Imagen 3},
	author={Baldridge, Jason and Bauer, Jakob and Bhutani, Mukul and Brichtova, Nicole and Bunner, Andrew and Castrejon, Lluis and Chan, Kelvin and Chen, Yichang and Dieleman, Sander and Du, Yuqing and others},
	journal={arXiv preprint arXiv:2408.07009},
	year={2024}
}
@misc{EcoDiff,
	title={Learnable Sparsity for Vision Generative Models}, 
	author={Yang Zhang and Er Jin and Wenzhong Liang and Yanfei Dong and Ashkan Khakzar and Philip Torr and Johannes Stegmaier and Kenji Kawaguchi},
	year={2025},
	eprint={2412.02852},
	archivePrefix={arXiv},
	primaryClass={cs.CV},
	url={https://arxiv.org/abs/2412.02852}, 
}

@software{kohya_ss_sd_scripts_2024,
	author       = {kohya-ss},
	title        = {sd-scripts},
	month        = oct,
	year         = 2024,
	publisher    = {GitHub},
	journal      = {GitHub repository},
	howpublished = {\url{https://github.com/kohya-ss/sd-scripts}},
}

@misc{pixartsigma_code,
	author = {Chen, Junsong and Ge, Chongjian and Xie, Enze and others},
	title = {PixArt-sigma: Official PyTorch Implementation},
	year = {2024},
	publisher = {GitHub},
	journal = {GitHub repository},
	howpublished = {\url{https://github.com/PixArt-alpha/PixArt-sigma}},
	commit = {INSERT_COMMIT_HASH_HERE} % Optional: Falls Sie eine spezifische Version genutzt haben
}

@article{dong2025attention,
	title={Attention Retrieves, MLP Memorizes: Disentangling Trainable Components in the Transformer},
	author={Dong, Yihe and Noci, Lorenzo and Khodak, Mikhail and Li, Mufan},
	journal={arXiv preprint arXiv:2506.01115},
	year={2025}
}

@article{ASVD,
	title={Asvd: Activation-aware singular value decomposition for compressing large language models},
	author={Yuan, Zhihang and Shang, Yuzhang and Song, Yue and Yang, Dawei and Wu, Qiang and Yan, Yan and Sun, Guangyu},
	journal={arXiv preprint arXiv:2312.05821},
	year={2023}
}

@article{kirstain2023pick,
	title={Pick-a-pic: An open dataset of user preferences for text-to-image generation},
	author={Kirstain, Yuval and Polyak, Adam and Singer, Uriel and Matiana, Shahbuland and Penna, Joe and Levy, Omer},
	journal={Advances in neural information processing systems},
	volume={36},
	pages={36652--36663},
	year={2023}
}

@article{zhang2015singular,
	title={The singular value decomposition, applications and beyond},
	author={Zhang, Zhihua},
	journal={arXiv preprint arXiv:1510.08532},
	year={2015}
}


@inproceedings{cordts2016cityscapes,
	title={The cityscapes dataset for semantic urban scene understanding},
	author={Cordts, Marius and Omran, Mohamed and Ramos, Sebastian and Rehfeld, Timo and Enzweiler, Markus and Benenson, Rodrigo and Franke, Uwe and Roth, Stefan and Schiele, Bernt},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={3213--3223},
	year={2016}
}

@inproceedings{neuhold2017mapillary,
	title={The mapillary vistas dataset for semantic understanding of street scenes},
	author={Neuhold, Gerhard and Ollmann, Tobias and Rota Bulo, Samuel and Kontschieder, Peter},
	booktitle={Proceedings of the IEEE international conference on computer vision},
	pages={4990--4999},
	year={2017}
}

@article{schuhmann2022laion,
	title={Laion-5b: An open large-scale dataset for training next generation image-text models},
	author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
	journal={Advances in neural information processing systems},
	volume={35},
	pages={25278--25294},
	year={2022}
}

@misc{fpgaminer2024joycaption,
	author       = {fpgaminer},
	title        = {{JoyCaption}: An open, uncensored Image Captioning {VLM}},
	howpublished = {\url{https://github.com/fpgaminer/joycaption}},
	year         = {2024},
	note         = {Accessed: 2026-01-22}
}

@misc{schuhmann2022laionaesthetic,
	author       = {Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
	title        = {{LAION-Aesthetic} V1},
	howpublished = {\url{https://github.com/LAION-AI/laion-datasets/blob/main/laion-aesthetic.md}},
	year         = {2022},
	note         = {Accessed: 2026-01-22}
}

@article{hu2022lora,
	title={Lora: Low-rank adaptation of large language models.},
	author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu and others},
	journal={ICLR},
	volume={1},
	number={2},
	pages={3},
	year={2022}
}\\

@inproceedings{pons2024effective,
	title={Effective layer pruning through similarity metric perspective},
	author={Pons, Ian and Yamamoto, Bruno and Reali Costa, Anna H and Jordao, Artur},
	booktitle={International Conference on Pattern Recognition},
	pages={423--438},
	year={2024},
	organization={Springer}
}

@article{jang2016categorical,
	title={Categorical reparameterization with gumbel-softmax},
	author={Jang, Eric and Gu, Shixiang and Poole, Ben},
	journal={arXiv preprint arXiv:1611.01144},
	year={2016}
}

@inproceedings{fang2025tinyfusion,
	title={Tinyfusion: Diffusion transformers learned shallow},
	author={Fang, Gongfan and Li, Kunjun and Ma, Xinyin and Wang, Xinchao},
	booktitle={Proceedings of the Computer Vision and Pattern Recognition Conference},
	pages={18144--18154},
	year={2025}
}

@article{davari2022reliability,
	title={Reliability of cka as a similarity measure in deep learning},
	author={Davari, MohammadReza and Horoi, Stefan and Natik, Amine and Lajoie, Guillaume and Wolf, Guy and Belilovsky, Eugene},
	journal={arXiv preprint arXiv:2210.16156},
	year={2022}
}

@inproceedings{gretton2005measuring,
	title={Measuring statistical dependence with Hilbert-Schmidt norms},
	author={Gretton, Arthur and Bousquet, Olivier and Smola, Alex and Sch{\"o}lkopf, Bernhard},
	booktitle={International conference on algorithmic learning theory},
	pages={63--77},
	year={2005},
	organization={Springer}
}
@inproceedings{kornblith2019similarity,
	title={Similarity of neural network representations revisited},
	author={Kornblith, Simon and Norouzi, Mohammad and Lee, Honglak and Hinton, Geoffrey},
	booktitle={International conference on machine learning},
	pages={3519--3529},
	year={2019},
	organization={PMlR}
}

@article{lee2020layer,
	title={Layer-adaptive sparsity for the magnitude-based pruning},
	author={Lee, Jaeho and Park, Sejun and Mo, Sangwoo and Ahn, Sungsoo and Shin, Jinwoo},
	journal={arXiv preprint arXiv:2010.07611},
	year={2020}
}

@inproceedings{akiba2019optuna,
	title={Optuna: A next-generation hyperparameter optimization framework},
	author={Akiba, Takuya and Sano, Shotaro and Yanase, Toshihiko and Ohta, Takeru and Koyama, Masanori},
	booktitle={Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery \& data mining},
	pages={2623--2631},
	year={2019}
}

@article{bergstra2011algorithms,
	title={Algorithms for hyper-parameter optimization},
	author={Bergstra, James and Bardenet, R{\'e}mi and Bengio, Yoshua and K{\'e}gl, Bal{\'a}zs},
	journal={Advances in neural information processing systems},
	volume={24},
	year={2011}
}

@inproceedings{liu2025grasp,
	title={GRASP: Replace Redundant Layers with Adaptive Singular Parameters for Efficient Model Compression},
	author={Liu, Kainan and Zhang, Yong and Cheng, Ning and Li, Zhitao and Wang, Shaojun and Xiao, Jing},
	booktitle={Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing},
	pages={26344--26359},
	year={2025}
}

@article{filters2016pruning,
	title={Pruning filters for efficient convnets},
	author={Filters’Importance, Determine},
	journal={arXiv preprint arXiv:1608.08710},
	year={2016}
}

@article{han2015learning,
	title={Learning both weights and connections for efficient neural network},
	author={Han, Song and Pool, Jeff and Tran, John and Dally, William},
	journal={Advances in neural information processing systems},
	volume={28},
	year={2015}
}

@misc{flux_mini_2024,
	author = {{TencentARC}},
	title = {flux-mini},
	year = {2024},
	publisher = {Hugging Face},
	howpublished = {\url{https://huggingface.co/TencentARC/flux-mini}},
	note = {Hugging Face Model Hub}
}

@article{flux1-lite,
	title={Flux.1 Lite: Distilling Flux1.dev for Efficient Text-to-Image Generation},
	author={Daniel Verdú, Javier Martín},
	email={dverdu@freepik.com, javier.martin@freepik.com},
	year={2024},
}


@inproceedings{Dense2MoE,
	title={Dense2moe: Restructuring diffusion transformer to moe for efficient text-to-image generation},
	author={Zheng, Youwei and Ren, Yuxi and Xia, Xin and Xiao, Xuefeng and Xie, Xiaohua},
	booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages={18661--18670},
	year={2025}
}

@article{ma2025pluggable,
	title={Pluggable Pruning with Contiguous Layer Distillation for Diffusion Transformers},
	author={Ma, Jian and Peng, Qirong and Zhu, Xujie and Xie, Peixing and Chen, Chen and Lu, Haonan},
	journal={arXiv preprint arXiv:2511.16156},
	year={2025}
}
@article{mplug,
	title={mPLUG: Effective and Efficient Vision-Language Learning by Cross-modal Skip-connections. arXiv 2022},
	author={Li, C and Xu, H and Tian, J and Wang, W and Yan, M and Bi, B and Ye, J and Chen, H and Xu, G and Cao, Z and others},
	journal={arXiv preprint arXiv:2205.12005},
	volume={1},
	year={2022}
}

@article{KnowledgeDistillation,
	title={Distilling the knowledge in a neural network},
	author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
	journal={arXiv preprint arXiv:1503.02531},
	year={2015}
}
@inproceedings{Objects365,
	title={Objects365: A large-scale, high-quality dataset for object detection},
	author={Shao, Shuai and Li, Zeming and Zhang, Tianyuan and Peng, Chao and Yu, Gang and Zhang, Xiangyu and Li, Jing and Sun, Jian},
	booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
	pages={8430--8439},
	year={2019}
}
@article{DSG,
	title={Davidsonian scene graph: Improving reliability in fine-grained evaluation for text-to-image generation},
	author={Cho, Jaemin and Hu, Yushi and Garg, Roopal and Anderson, Peter and Krishna, Ranjay and Baldridge, Jason and Bansal, Mohit and Pont-Tuset, Jordi and Wang, Su},
	journal={arXiv preprint arXiv:2310.18235},
	year={2023}
}

@article{DPG,
	title={Ella: Equip diffusion models with llm for enhanced semantic alignment},
	author={Hu, Xiwei and Wang, Rui and Fang, Yixiao and Fu, Bin and Cheng, Pei and Yu, Gang},
	journal={arXiv preprint arXiv:2403.05135},
	year={2024}
}


@inproceedings{DiT,
	title={Scalable diffusion models with transformers},
	author={Peebles, William and Xie, Saining},
	booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
	pages={4195--4205},
	year={2023}
}

@article{Pixart_d,
	title={Pixart-$\delta$: Fast and controllable image generation with latent consistency models},
	author={Chen, Junsong and Wu, Yue and Luo, Simian and Xie, Enze and Paul, Sayak and Luo, Ping and Zhao, Hang and Li, Zhenguo},
	journal={arXiv preprint arXiv:2401.05252},
	year={2024}
}

@article{Pixart_a,
	title={Pixart-$\alpha$: Fast training of diffusion transformer for photorealistic text-to-image synthesis},
	author={Chen, Junsong and Yu, Jincheng and Ge, Chongjian and Yao, Lewei and Xie, Enze and Wu, Yue and Wang, Zhongdao and Kwok, James and Luo, Ping and Lu, Huchuan and others},
	journal={arXiv preprint arXiv:2310.00426},
	year={2023}
}
@article{ghosh2023geneval,
	title={Geneval: An object-focused framework for evaluating text-to-image alignment},
	author={Ghosh, Dhruba and Hajishirzi, Hannaneh and Schmidt, Ludwig},
	journal={Advances in Neural Information Processing Systems},
	volume={36},
	pages={52132--52152},
	year={2023}
}
@inproceedings{DiffusionDB,
	title={Diffusiondb: A large-scale prompt gallery dataset for text-to-image generative models},
	author={Wang, Zijie J and Montoya, Evan and Munechika, David and Yang, Haoyang and Hoover, Benjamin and Chau, Duen Horng},
	booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
	pages={893--911},
	year={2023}
}
@article{COCO,
	title={Microsoft coco captions: Data collection and evaluation server},
	author={Chen, Xinlei and Fang, Hao and Lin, Tsung-Yi and Vedantam, Ramakrishna and Gupta, Saurabh and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
	journal={arXiv preprint arXiv:1504.00325},
	year={2015}
}
@article{HPSv2,
	title={Human preference score v2: A solid benchmark for evaluating human preferences of text-to-image synthesis},
	author={Wu, Xiaoshi and Hao, Yiming and Sun, Keqiang and Chen, Yixiong and Zhu, Feng and Zhao, Rui and Li, Hongsheng},
	journal={arXiv preprint arXiv:2306.09341},
	year={2023}
}
@inproceedings{CLIP,
	title={Learning transferable visual models from natural language supervision},
	author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
	booktitle={International conference on machine learning},
	pages={8748--8763},
	year={2021},
	organization={PmLR}
}
@article{MMD2,
	title={A kernel two-sample test},
	author={Gretton, Arthur and Borgwardt, Karsten M and Rasch, Malte J and Sch{\"o}lkopf, Bernhard and Smola, Alexander},
	journal={The journal of machine learning research},
	volume={13},
	number={1},
	pages={723--773},
	year={2012},
	publisher={JMLR. org}
}
@inproceedings{cmmd,
	title={Rethinking fid: Towards a better evaluation metric for image generation},
	author={Jayasumana, Sadeep and Ramalingam, Srikumar and Veit, Andreas and Glasner, Daniel and Chakrabarti, Ayan and Kumar, Sanjiv},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={9307--9315},
	year={2024}
}
@inproceedings{szegedy2016rethinking,
	title={Rethinking the inception architecture for computer vision},
	author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={2818--2826},
	year={2016}
}
@article{dowson1982frechet,
	title={The Fr{\'e}chet distance between multivariate normal distributions},
	author={Dowson, DC and Landau, BV666017},
	journal={Journal of multivariate analysis},
	volume={12},
	number={3},
	pages={450--455},
	year={1982},
	publisher={Elsevier}
}
@article{FID,
	title={Gans trained by a two time-scale update rule converge to a local nash equilibrium},
	author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
	journal={Advances in neural information processing systems},
	volume={30},
	year={2017}
}
@article{GPT4,
   author = {Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal},
   title = {Gpt-4 technical report},
   journal = {arXiv preprint arXiv:2303.08774},
   year = {2023},
   type = {Journal Article}
}

@article{Claude,
   author = {Anthropic},
   title = {Claude 3 Haiku: our fastest model yet},
   url = {https://www.anthropic.com/news/claude-3-haiku},
   year = {2024},
   type = {Journal Article}
}

@article{VQVAE,
	author = {Van Den Oord, Aaron and Vinyals, Oriol},
	title = {Neural discrete representation learning},
	journal = {Advances in neural information processing systems},
	volume = {30},
	year = {2017},
	type = {Journal Article}
}

@inproceedings{ControlNet,
	title={Adding conditional control to text-to-image diffusion models},
	author={Zhang, Lvmin and Rao, Anyi and Agrawala, Maneesh},
	booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
	pages={3836--3847},
	year={2023}
} 
@article{Gemini,
   author = {Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and Millican, Katie},
   title = {Gemini: a family of highly capable multimodal models},
   journal = {arXiv preprint arXiv:2312.11805},
   year = {2023},
   type = {Journal Article}
}

@article{Lama,
   author = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti},
   title = {Llama 2: Open foundation and fine-tuned chat models},
   journal = {arXiv preprint arXiv:2307.09288},
   year = {2023},
   type = {Journal Article}
}


% Diffusion Models

@inproceedings{SD21,
   author = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Björn},
   title = {High-resolution image synthesis with latent diffusion models},
   booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
   pages = {10684-10695},
   type = {Conference Proceedings}
}

@article{SDXL,
   author = {Podell, Dustin and English, Zion and Lacey, Kyle and Blattmann, Andreas and Dockhorn, Tim and Müller, Jonas and Penna, Joe and Rombach, Robin},
   title = {Sdxl: Improving latent diffusion models for high-resolution image synthesis},
   journal = {arXiv preprint arXiv:2307.01952},
   year = {2023},
   type = {Journal Article}
}

@inproceedings{Pixart_s,
   author = {Chen, Junsong and Ge, Chongjian and Xie, Enze and Wu, Yue and Yao, Lewei and Ren, Xiaozhe and Wang, Zhongdao and Luo, Ping and Lu, Huchuan and Li, Zhenguo},
   title = {Pixart-$\sigma$: Weak-to-strong training of diffusion transformer for 4k text-to-image generation},
   booktitle = {European Conference on Computer Vision},
   publisher = {Springer},
   pages = {74-91},
   type = {Conference Proceedings}
}

@article{Flux,
   author = {Labs, Black Forest},
   title = {Flux Model},
   url = {https://bfl.ai},
   year = {2024},
   type = {Journal Article}
}

@article{HiDream,
   author = {AI, Vivago},
   title = {HiDream-l1},
   url = {https://vivago.ai/home},
   year = {2025},
   type = {Journal Article}
}

% Diffusion Model Fundamentals
@inproceedings{DMBeginning,
   author = {Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
   title = {Deep unsupervised learning using nonequilibrium thermodynamics},
   booktitle = {International conference on machine learning},
   publisher = {pmlr},
   pages = {2256-2265},
   type = {Conference Proceedings}
}

% General Generative Models
@misc{VAE,
   author = {Kingma, Diederik P and Welling, Max},
   title = {Auto-encoding variational bayes},
   publisher = {Banff, Canada},
   year = {2013},
   type = {Generic}
}

@article{AE,
   author = {Hinton, Geoffrey E and Salakhutdinov, Ruslan R},
   title = {Reducing the dimensionality of data with neural networks},
   journal = {science},
   volume = {313},
   number = {5786},
   pages = {504-507},
   ISSN = {0036-8075},
   year = {2006},
   type = {Journal Article}
}

@article{KL-Div,
   author = {Kullback, Solomon and Leibler, Richard A},
   title = {On information and sufficiency},
   journal = {The annals of mathematical statistics},
   volume = {22},
   number = {1},
   pages = {79-86},
   ISSN = {0003-4851},
   year = {1951},
   type = {Journal Article}
}

@article{ELBO,
   author = {Blei, David M and Kucukelbir, Alp and McAuliffe, Jon D},
   title = {Variational inference: A review for statisticians},
   journal = {Journal of the American statistical Association},
   volume = {112},
   number = {518},
   pages = {859-877},
   ISSN = {0162-1459},
   year = {2017},
   type = {Journal Article}
}




@article{GAN,
   author = {Goodfellow, Ian J and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
   title = {Generative adversarial nets},
   journal = {Advances in neural information processing systems},
   volume = {27},
   year = {2014},
   type = {Journal Article}
}

@inproceedings{WGAN,
   author = {Arjovsky, Martin and Chintala, Soumith and Bottou, Léon},
   title = {Wasserstein generative adversarial networks},
   booktitle = {International conference on machine learning},
   publisher = {PMLR},
   pages = {214-223},
   ISBN = {2640-3498},
   type = {Conference Proceedings}
}


@article{ConvGAN,
   author = {Radford, Alec and Metz, Luke and Chintala, Soumith},
   title = {Unsupervised representation learning with deep convolutional generative adversarial networks},
   journal = {arXiv preprint arXiv:1511.06434},
   year = {2015},
   type = {Journal Article}
}

@inproceedings{FastGAN,
   author = {Liu, Bingchen and Zhu, Yizhe and Song, Kunpeng and Elgammal, Ahmed},
   title = {Towards Faster and Stabilized GAN Training for High-fidelity Few-shot Image Synthesis},
   booktitle = {iclr},
   type = {Conference Proceedings}
}

@article{StyleGAN_3,
   author = {Karras, Tero and Aittala, Miika and Laine, Samuli and Härkönen, Erik and Hellsten, Janne and Lehtinen, Jaakko and Aila, Timo},
   title = {Alias-free generative adversarial networks},
   journal = {Advances in neural information processing systems},
   volume = {34},
   pages = {852-863},
   year = {2021},
   type = {Journal Article}
}

@inproceedings{StyleGAN_T,
   author = {Sauer, Axel and Karras, Tero and Laine, Samuli and Geiger, Andreas and Aila, Timo},
   title = {Stylegan-t: Unlocking the power of gans for fast large-scale text-to-image synthesis},
   booktitle = {International conference on machine learning},
   publisher = {PMLR},
   pages = {30105-30118},
   ISBN = {2640-3498},
   type = {Conference Proceedings}
}

@article{ImprovedGANTraining,
   author = {Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
   title = {Improved techniques for training gans},
   journal = {Advances in neural information processing systems},
   volume = {29},
   year = {2016},
   type = {Journal Article}
}

@article{PacGAN,
   author = {Lin, Zinan and Khetan, Ashish and Fanti, Giulia and Oh, Sewoong},
   title = {Pacgan: The power of two samples in generative adversarial networks},
   journal = {Advances in neural information processing systems},
   volume = {31},
   year = {2018},
   type = {Journal Article}
}

@inproceedings{ModeCollapse1,
   author = {Thanh-Tung, Hoang and Tran, Truyen},
   title = {Catastrophic forgetting and mode collapse in GANs},
   booktitle = {2020 international joint conference on neural networks (ijcnn)},
   publisher = {IEEE},
   pages = {1-10},
   ISBN = {1728169267},
   type = {Conference Proceedings}
}

@inproceedings{BERT,
   author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
   title = {Bert: Pre-training of deep bidirectional transformers for language understanding},
   booktitle = {Proceedings of the 2019 conference of the North American chapter of the association for computational linguistics: human language technologies, volume 1 (long and short papers)},
   pages = {4171-4186},
   type = {Conference Proceedings}
}

@inproceedings{ResidualConnection,
   author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
   title = {Deep residual learning for image recognition},
   booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
   pages = {770-778},
   type = {Conference Proceedings}
}
@article{OrgAttention,
   author = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
   title = {Neural machine translation by jointly learning to align and translate},
   journal = {arXiv preprint arXiv:1409.0473},
   year = {2014},
   type = {Journal Article}
}
@article{SelfAttentionFigure,
   author = {Raschka, Sebastian},
   title = {Understanding and Coding the Self-Attention Mechanism of Large Language Models From Scratch},
   url = {https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html},
   year = {2023},
   type = {Journal Article}
}
@article{Reformer,
   author = {Kitaev, Nikita and Kaiser, Łukasz and Levskaya, Anselm},
   title = {Reformer: The efficient transformer},
   journal = {arXiv preprint arXiv:2001.04451},
   year = {2020},
   type = {Journal Article}
}
@article{SparseTransformer,
   author = {Child, Rewon and Gray, Scott and Radford, Alec and Sutskever, Ilya},
   title = {Generating long sequences with sparse transformers},
   journal = {arXiv preprint arXiv:1904.10509},
   year = {2019},
   type = {Journal Article}
}
@article{FlashAttention,
   author = {Dao, Tri and Fu, Dan and Ermon, Stefano and Rudra, Atri and Ré, Christopher},
   title = {Flashattention: Fast and memory-efficient exact attention with io-awareness},
   journal = {Advances in neural information processing systems},
   volume = {35},
   pages = {16344-16359},
   year = {2022},
   type = {Journal Article}
}




@article{Performer,
   author = {Choromanski, Krzysztof and Likhosherstov, Valerii and Dohan, David and Song, Xingyou and Gane, Andreea and Sarlos, Tamas and Hawkins, Peter and Davis, Jared and Mohiuddin, Afroz and Kaiser, Lukasz},
   title = {Rethinking attention with performers},
   journal = {arXiv preprint arXiv:2009.14794},
   year = {2020},
   type = {Journal Article}
}




@article{LayerNorm,
   author = {Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
   title = {Layer normalization},
   journal = {arXiv preprint arXiv:1607.06450},
   year = {2016},
   type = {Journal Article}
}





@inproceedings{NormalizingFlow,
   author = {Rezende, Danilo and Mohamed, Shakir},
   title = {Variational inference with normalizing flows},
   booktitle = {International conference on machine learning},
   publisher = {PMLR},
   pages = {1530-1538},
   type = {Conference Proceedings}
}

@article{AffineCouplingLayer,
   author = {Dinh, Laurent and Krueger, David and Bengio, Yoshua},
   title = {Nice: Non-linear independent components estimation},
   journal = {arXiv preprint arXiv:1410.8516},
   year = {2014},
   type = {Journal Article}
}


@article{AttentionIsAllYouNeed,
   author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
   title = {Attention is all you need},
   journal = {Advances in neural information processing systems},
   volume = {30},
   year = {2017},
   type = {Journal Article}
}

@article{RNN,
   author = {Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
   title = {Learning representations by back-propagating errors},
   journal = {nature},
   volume = {323},
   number = {6088},
   pages = {533-536},
   ISSN = {0028-0836},
   year = {1986},
   type = {Journal Article}
}


@inproceedings{ALiBi,
   author = {Park, Joon Sung and O'Brien, Joseph and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
   title = {Generative agents: Interactive simulacra of human behavior},
   booktitle = {Proceedings of the 36th annual acm symposium on user interface software and technology},
   pages = {1-22},
   type = {Conference Proceedings}
}

@article{Cape,
   author = {Likhomanenko, Tatiana and Xu, Qiantong and Synnaeve, Gabriel and Collobert, Ronan and Rogozhnikov, Alex},
   title = {Cape: Encoding relative positions with continuous augmented positional embeddings},
   journal = {Advances in Neural Information Processing Systems},
   volume = {34},
   pages = {16079-16092},
   year = {2021},
   type = {Journal Article}
}

@article{FIRE,
   author = {Li, Shanda and You, Chong and Guruganesh, Guru and Ainslie, Joshua and Ontanon, Santiago and Zaheer, Manzil and Sanghai, Sumit and Yang, Yiming and Kumar, Sanjiv and Bhojanapalli, Srinadh},
   title = {Functional interpolation for relative positions improves long context transformers},
   journal = {arXiv preprint arXiv:2310.04418},
   year = {2023},
   type = {Journal Article}
}

@inproceedings{Floater,
   author = {Liu, Xuanqing and Yu, Hsiang-Fu and Dhillon, Inderjit and Hsieh, Cho-Jui},
   title = {Learning to encode position for transformer with continuous dynamical model},
   booktitle = {International conference on machine learning},
   publisher = {PMLR},
   pages = {6327-6335},
   ISBN = {2640-3498},
   type = {Conference Proceedings}
}

@article{RoPE,
   author = {Su, Jianlin and Ahmed, Murtadha and Lu, Yu and Pan, Shengfeng and Bo, Wen and Liu, Yunfeng},
   title = {Roformer: Enhanced transformer with rotary position embedding},
   journal = {Neurocomputing},
   volume = {568},
   pages = {127063},
   ISSN = {0925-2312},
   year = {2024},
   type = {Journal Article}
}

@article{Shape,
   author = {Kiyono, Shun and Kobayashi, Sosuke and Suzuki, Jun and Inui, Kentaro},
   title = {Shape: Shifted absolute position embedding for transformers},
   journal = {arXiv preprint arXiv:2109.05644},
   year = {2021},
   type = {Journal Article}
}

@article{PositionalEmbeddingSurvey,
   author = {Zhao, Liang and Feng, Xiachong and Feng, Xiaocheng and Zhong, Weihong and Xu, Dongliang and Yang, Qing and Liu, Hongtao and Qin, Bing and Liu, Ting},
   title = {Length extrapolation of transformers: A survey from the perspective of positional encoding},
   journal = {arXiv preprint arXiv:2312.17044},
   year = {2023},
   type = {Journal Article}
}

@article{VisionTransformer,
   author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain},
   title = {An image is worth 16x16 words: Transformers for image recognition at scale},
   journal = {arXiv preprint arXiv:2010.11929},
   year = {2020},
   type = {Journal Article}
}

@inproceedings{Ccnet,
   author = {Huang, Zilong and Wang, Xinggang and Huang, Lichao and Huang, Chang and Wei, Yunchao and Liu, Wenyu},
   title = {Ccnet: Criss-cross attention for semantic segmentation},
   booktitle = {Proceedings of the IEEE/CVF international conference on computer vision},
   pages = {603-612},
   type = {Conference Proceedings}
}

@inproceedings{ImageTransformer,
   author = {Parmar, Niki and Vaswani, Ashish and Uszkoreit, Jakob and Kaiser, Lukasz and Shazeer, Noam and Ku, Alexander and Tran, Dustin},
   title = {Image transformer},
   booktitle = {International conference on machine learning},
   publisher = {PMLR},
   pages = {4055-4064},
   ISBN = {2640-3498},
   type = {Conference Proceedings}
}

@article{StandAloneAttentionVisonModels,
   author = {Ramachandran, Prajit and Parmar, Niki and Vaswani, Ashish and Bello, Irwan and Levskaya, Anselm and Shlens, Jon},
   title = {Stand-alone self-attention in vision models},
   journal = {Advances in neural information processing systems},
   volume = {32},
   year = {2019},
   type = {Journal Article}
}

@article{CNN,
   author = {Ramachandran, Prajit and Parmar, Niki and Vaswani, Ashish and Bello, Irwan and Levskaya, Anselm and Shlens, Jon},
   title = {Stand-alone self-attention in vision models},
   journal = {Advances in neural information processing systems},
   volume = {32},
   year = {2019},
   type = {Journal Article}
}

@inproceedings{ADD,
   author = {Sauer, Axel and Lorenz, Dominik and Blattmann, Andreas and Rombach, Robin},
   title = {Adversarial diffusion distillation},
   booktitle = {European Conference on Computer Vision},
   publisher = {Springer},
   pages = {87-103},
   type = {Conference Proceedings}
}

@article{ConsistencyModel,
   author = {Song, Yang and Dhariwal, Prafulla and Chen, Mark and Sutskever, Ilya},
   title = {Consistency models},
   year = {2023},
   type = {Journal Article}
}

@inproceedings{DistillationMatching,
   author = {Yin, Tianwei and Gharbi, Michaël and Zhang, Richard and Shechtman, Eli and Durand, Fredo and Freeman, William T and Park, Taesung},
   title = {One-step diffusion with distribution matching distillation},
   booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
   pages = {6613-6623},
   type = {Conference Proceedings}
}

@inproceedings{DistillDifModelCGAN,
   author = {Kang, Minguk and Zhang, Richard and Barnes, Connelly and Paris, Sylvain and Kwak, Suha and Park, Jaesik and Shechtman, Eli and Zhu, Jun-Yan and Park, Taesung},
   title = {Distilling diffusion models into conditional gans},
   booktitle = {European Conference on Computer Vision},
   publisher = {Springer},
   pages = {428-447},
   type = {Conference Proceedings}
}

@inproceedings{GuidedDistillation,
   author = {Meng, Chenlin and Rombach, Robin and Gao, Ruiqi and Kingma, Diederik and Ermon, Stefano and Ho, Jonathan and Salimans, Tim},
   title = {On distillation of guided diffusion models},
   booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
   pages = {14297-14306},
   type = {Conference Proceedings}
}

@article{ImprovedDistillationMatching,
   author = {Yin, Tianwei and Gharbi, Michaël and Park, Taesung and Zhang, Richard and Shechtman, Eli and Durand, Fredo and Freeman, Bill},
   title = {Improved distribution matching distillation for fast image synthesis},
   journal = {Advances in neural information processing systems},
   volume = {37},
   pages = {47455-47487},
   year = {2024},
   type = {Journal Article}
}

@inproceedings{LADD,
   author = {Sauer, Axel and Boesel, Frederic and Dockhorn, Tim and Blattmann, Andreas and Esser, Patrick and Rombach, Robin},
   title = {Fast high-resolution image synthesis with latent adversarial diffusion distillation},
   booktitle = {SIGGRAPH Asia 2024 Conference Papers},
   pages = {1-11},
   type = {Conference Proceedings}
}

@article{LatentConsistencyModel,
   author = {Luo, Simian and Tan, Yiqin and Huang, Longbo and Li, Jian and Zhao, Hang},
   title = {Latent consistency models: Synthesizing high-resolution images with few-step inference},
   journal = {arXiv preprint arXiv:2310.04378},
   year = {2023},
   type = {Journal Article}
}

@article{SDXL_Lightning,
   author = {Lin, Shanchuan and Wang, Anran and Yang, Xiao},
   title = {Sdxl-lightning: Progressive adversarial diffusion distillation},
   journal = {arXiv preprint arXiv:2402.13929},
   year = {2024},
   type = {Journal Article}
}

@article{ProgressiveDistillation,
   author = {Salimans, Tim and Ho, Jonathan},
   title = {Progressive distillation for fast sampling of diffusion models},
   journal = {arXiv preprint arXiv:2202.00512},
   year = {2022},
   type = {Journal Article}
}


@inproceedings{Bksdm,
   author = {Kim, Bo-Kyeong and Song, Hyoung-Kyu and Castells, Thibault and Choi, Shinkook},
   title = {Bk-sdm: A lightweight, fast, and cheap version of stable diffusion},
   booktitle = {European Conference on Computer Vision},
   publisher = {Springer},
   pages = {381-399},
   type = {Conference Proceedings}
}

@article{Koala,
   author = {Lee, Youngwan and Park, Kwanyong and Cho, Yoorhim and Lee, Yong-Ju and Hwang, Sung Ju},
   title = {Koala: Empirical lessons toward memory-efficient and fast diffusion models for text-to-image synthesis},
   journal = {Advances in Neural Information Processing Systems},
   volume = {37},
   pages = {51597-51633},
   year = {2024},
   type = {Journal Article}
}
@article{Laptop,
   author = {Zhang, Dingkun and Li, Sijia and Chen, Chen and Xie, Qingsong and Lu, Haonan},
   title = {Laptop-diff: Layer pruning and normalized distillation for compressing diffusion models},
   journal = {arXiv preprint arXiv:2404.11098},
   year = {2024},
   type = {Journal Article}
}


@article{DinoV2,
   author = {Oquab, Maxime and Darcet, Timothée and Moutakanni, Théo and Vo, Huy and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and Haziza, Daniel and Massa, Francisco and El-Nouby, Alaaeldin},
   title = {Dinov2: Learning robust visual features without supervision},
   journal = {arXiv preprint arXiv:2304.07193},
   year = {2023},
   type = {Journal Article}
}


@article{ScoreBasedDiffModel,
   author = {Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
   title = {Score-based generative modeling through stochastic differential equations},
   journal = {arXiv preprint arXiv:2011.13456},
   year = {2020},
   type = {Journal Article}
}

@inproceedings{LPIPS,
   author = {Zhang, Richard and Isola, Phillip and Efros, Alexei A and Shechtman, Eli and Wang, Oliver},
   title = {The unreasonable effectiveness of deep features as a perceptual metric},
   booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
   pages = {586-595},
   type = {Conference Proceedings}
}


@article{BatchNorm,
	title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
	author={Ioffe, Sergey},
	journal={arXiv preprint arXiv:1502.03167},
	year={2015}
}
@article{KnowledgeDistillation,
   author = {Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
   title = {Distilling the knowledge in a neural network},
   journal = {arXiv preprint arXiv:1503.02531},
   year = {2015},
   type = {Journal Article}
}

@inproceedings{Unet,
   author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
   title = {U-net: Convolutional networks for biomedical image segmentation},
   booktitle = {Medical image computing and computer-assisted intervention–MICCAI 2015: 18th international conference, Munich, Germany, October 5-9, 2015, proceedings, part III 18},
   publisher = {Springer},
   pages = {234-241},
   ISBN = {3319245732},
   type = {Conference Proceedings}
}



@inproceedings{DiffusionModelIntroPaper,
   author = {Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
   title = {Deep unsupervised learning using nonequilibrium thermodynamics},
   booktitle = {International conference on machine learning},
   publisher = {pmlr},
   pages = {2256-2265},
   type = {Conference Proceedings}
}


@misc{DDPM,
   author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
   title = {Denoising Diffusion Probabilistic Models},
   pages = {arXiv:2006.11239},
   month = {June 01, 2020},
   abstract = {We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN. Our implementation is available at https://github.com/hojonathanho/diffusion},
   keywords = {Computer Science - Machine Learning
Statistics - Machine Learning},
   DOI = {10.48550/arXiv.2006.11239},
   url = {https://ui.adsabs.harvard.edu/abs/2020arXiv200611239H},
   year = {2020},
   type = {Electronic Article}
}

@article{CNF,
	title={Neural ordinary differential equations},
	author={Chen, Ricky TQ and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David K},
	journal={Advances in neural information processing systems},
	volume={31},
	year={2018}
}

@article{RMSNorm,
	title={Root mean square layer normalization},
	author={Zhang, Biao and Sennrich, Rico},
	journal={Advances in neural information processing systems},
	volume={32},
	year={2019}
}

@misc{DDIM,
   author = {Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
   title = {Denoising Diffusion Implicit Models},
   pages = {arXiv:2010.02502},
   month = {October 01, 2020},
   note = {ICLR 2021; updated connections with ODEs at page 6, fixed some typos in the proof},
   abstract = {Denoising diffusion probabilistic models (DDPMs) have achieved high quality image generation without adversarial training, yet they require simulating a Markov chain for many steps to produce a sample. To accelerate sampling, we present denoising diffusion implicit models (DDIMs), a more efficient class of iterative implicit probabilistic models with the same training procedure as DDPMs. In DDPMs, the generative process is defined as the reverse of a Markovian diffusion process. We construct a class of non-Markovian diffusion processes that lead to the same training objective, but whose reverse process can be much faster to sample from. We empirically demonstrate that DDIMs can produce high quality samples $10 \times$ to $50 \times$ faster in terms of wall-clock time compared to DDPMs, allow us to trade off computation for sample quality, and can perform semantically meaningful image interpolation directly in the latent space.},
   keywords = {Computer Science - Machine Learning
Computer Science - Computer
Vision and Pattern Recognition},
   DOI = {10.48550/arXiv.2010.02502},
   url = {https://ui.adsabs.harvard.edu/abs/2020arXiv201002502S},
   year = {2020},
   type = {Electronic Article}
}

@misc{LDM,
   author = {Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Björn},
   title = {High-Resolution Image Synthesis with Latent Diffusion Models},
   pages = {arXiv:2112.10752},
   month = {December 01, 2021},
   note = {CVPR 2022},
   abstract = {By decomposing the image formation process into a sequential application of denoising autoencoders, diffusion models (DMs) achieve state-of-the-art synthesis results on image data and beyond. Additionally, their formulation allows for a guiding mechanism to control the image generation process without retraining. However, since these models typically operate directly in pixel space, optimization of powerful DMs often consumes hundreds of GPU days and inference is expensive due to sequential evaluations. To enable DM training on limited computational resources while retaining their quality and flexibility, we apply them in the latent space of powerful pretrained autoencoders. In contrast to previous work, training diffusion models on such a representation allows for the first time to reach a near-optimal point between complexity reduction and detail preservation, greatly boosting visual fidelity. By introducing cross-attention layers into the model architecture, we turn diffusion models into powerful and flexible generators for general conditioning inputs such as text or bounding boxes and high-resolution synthesis becomes possible in a convolutional manner. Our latent diffusion models (LDMs) achieve a new state of the art for image inpainting and highly competitive performance on various tasks, including unconditional image generation, semantic scene synthesis, and super-resolution, while significantly reducing computational requirements compared to pixel-based DMs. Code is available at https://github.com/CompVis/latent-diffusion .},
   keywords = {Computer Science - Computer Vision and Pattern Recognition},
   DOI = {10.48550/arXiv.2112.10752},
   url = {https://ui.adsabs.harvard.edu/abs/2021arXiv211210752R},
   year = {2021},
   type = {Electronic Article}
}

@article{LLaVA,
	title={Visual instruction tuning},
	author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
	journal={Advances in neural information processing systems},
	volume={36},
	pages={34892--34916},
	year={2023}
}

@inproceedings{chen2024sharegpt4v,
	title={Sharegpt4v: Improving large multi-modal models with better captions},
	author={Chen, Lin and Li, Jinsong and Dong, Xiaoyi and Zhang, Pan and He, Conghui and Wang, Jiaqi and Zhao, Feng and Lin, Dahua},
	booktitle={European Conference on Computer Vision},
	pages={370--387},
	year={2024},
	organization={Springer}
}
@article{FastFlux,
	title={FastFLUX: Pruning FLUX with Block-wise Replacement and Sandwich Training},
	author={Cai, Fuhan and Guo, Yong and Li, Jie and Li, Wenbo and Fang, Xiangzhong and Chen, Jian},
	journal={arXiv preprint arXiv:2506.10035},
	year={2025}
}
@inproceedings{ImageNet,
	title={Imagenet: A large-scale hierarchical image database},
	author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
	booktitle={2009 IEEE conference on computer vision and pattern recognition},
	pages={248--255},
	year={2009},
	organization={Ieee}
}
@inproceedings{SAM,
	title={Segment anything},
	author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
	booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
	pages={4015--4026},
	year={2023}
}

@inproceedings{SD3,
	title={Scaling rectified flow transformers for high-resolution image synthesis},
	author={Esser, Patrick and Kulal, Sumith and Blattmann, Andreas and Entezari, Rahim and M{\"u}ller, Jonas and Saini, Harry and Levi, Yam and Lorenz, Dominik and Sauer, Axel and Boesel, Frederic and others},
	booktitle={Forty-first international conference on machine learning},
	year={2024}
}


@inproceedings{adaLN,
	title={Film: Visual reasoning with a general conditioning layer},
	author={Perez, Ethan and Strub, Florian and De Vries, Harm and Dumoulin, Vincent and Courville, Aaron},
	booktitle={Proceedings of the AAAI conference on artificial intelligence},
	volume={32},
	number={1},
	year={2018}
}
@article{SDE,
   author = {Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
   title = {Score-based generative modeling through stochastic differential equations},
   journal = {arXiv preprint arXiv:2011.13456},
   year = {2020},
   type = {Journal Article}
}

@article{SGM,
   author = {Song, Yang and Ermon, Stefano},
   title = {Generative modeling by estimating gradients of the data distribution},
   journal = {Advances in neural information processing systems},
   volume = {32},
   year = {2019},
   type = {Journal Article}
}


@article{SurveyDM,
   author = {Croitoru, Florinel-Alin and Hondru, Vlad and Ionescu, Radu Tudor and Shah, Mubarak},
   title = {Diffusion models in vision: A survey},
   journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
   volume = {45},
   number = {9},
   pages = {10850-10869},
   ISSN = {0162-8828},
   year = {2023},
   type = {Journal Article}
}

@article{RectifiedFlowMatching,
   author = {Liu, Xingchao and Gong, Chengyue and Liu, Qiang},
   title = {Flow straight and fast: Learning to generate and transfer data with rectified flow},
   journal = {arXiv preprint arXiv:2209.03003},
   year = {2022},
   type = {Journal Article}
}


@article{FlowMatching,
   author = {Lipman, Yaron and Chen, Ricky TQ and Ben-Hamu, Heli and Nickel, Maximilian and Le, Matt},
   title = {Flow matching for generative modeling},
   journal = {arXiv preprint arXiv:2210.02747},
   year = {2022},
   type = {Journal Article}
}

@inproceedings{ImprovedDDPM,
   author = {Nichol, Alexander Quinn and Dhariwal, Prafulla},
   title = {Improved denoising diffusion probabilistic models},
   booktitle = {International conference on machine learning},
   publisher = {PMLR},
   pages = {8162-8171},
   ISBN = {2640-3498},
   type = {Conference Proceedings}
}

@article{VDM,
   author = {Kingma, Diederik and Salimans, Tim and Poole, Ben and Ho, Jonathan},
   title = {Variational diffusion models},
   journal = {Advances in neural information processing systems},
   volume = {34},
   pages = {21696-21707},
   year = {2021},
   type = {Journal Article}
}


@inproceedings{feller1949stochastic,
  author    = {Feller, William},
  title     = {On the Theory of Stochastic Processes, with Particular Reference to Applications},
  booktitle = {Proceedings of the First Berkeley Symposium on Mathematical Statistics and Probability},
  year      = {1949},
  publisher = {The Regents of the University of California},
  address   = {Berkeley, CA},
  pages     = {403--432}
}

@misc{pawlowski2024physics,
  author       = {Jan Pawlowski and Tilman Plehn},
  title        = {Physics and Machine Learning},
  howpublished = {Lecture script, Institut für Theoretische Physik, Universität Heidelberg},
  year         = {2024},
  month        = {January},
  note         = {Version from January 30, 2024}
}


@article{DDPMSamplerImage,
   author = {Butter, Anja and Huetsch, Nathan and Palacios Schweitzer, Sofia and Plehn, Tilman and Sorrenson, Peter and Spinner, Jonas},
   title = {Jet diffusion versus JetGPT–modern networks for the LHC},
   journal = {SciPost Physics Core},
   volume = {8},
   number = {1},
   pages = {026},
   ISSN = {2666-9366},
   year = {2025},
   type = {Journal Article}
}

@article{LectureNotesDDPM,
   author = {Strümke, Inga and Langseth, Helge},
   title = {Lecture Notes in Probabilistic Diffusion Models},
   journal = {arXiv preprint arXiv:2312.10393},
   year = {2023},
   type = {Journal Article}
}

@article{IntroSGM,
   author = {Song, Yang and Ermon, Stefano},
   title = {Generative modeling by estimating gradients of the data distribution},
   journal = {Advances in neural information processing systems},
   volume = {32},
   year = {2019},
   type = {Journal Article}
}

@article{ImprovedSGMs,
   author = {Song, Yang and Ermon, Stefano},
   title = {Improved techniques for training score-based generative models},
   journal = {Advances in neural information processing systems},
   volume = {33},
   pages = {12438-12448},
   year = {2020},
   type = {Journal Article}
}


@article{Survey2,
   author = {Yang, Ling and Zhang, Zhilong and Song, Yang and Hong, Shenda and Xu, Runsheng and Zhao, Yue and Zhang, Wentao and Cui, Bin and Yang, Ming-Hsuan},
   title = {Diffusion models: A comprehensive survey of methods and applications},
   journal = {ACM Computing Surveys},
   volume = {56},
   number = {4},
   pages = {1-39},
   ISSN = {0360-0300},
   year = {2023},
   type = {Journal Article}
}


@article{ScoreBasedODE,
   author = {Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
   title = {Score-based generative modeling through stochastic differential equations},
   journal = {arXiv preprint arXiv:2011.13456},
   year = {2020},
   type = {Journal Article}
}

@inproceedings{SlicedScoreMatching,
   author = {Song, Yang and Garg, Sahaj and Shi, Jiaxin and Ermon, Stefano},
   title = {Sliced score matching: A scalable approach to density and score estimation},
   booktitle = {Uncertainty in artificial intelligence},
   publisher = {PMLR},
   pages = {574-584},
   ISBN = {2640-3498},
   type = {Conference Proceedings}
}

@inproceedings{SteinDiscrepancy,
   author = {Gorham, Jackson and Mackey, Lester},
   title = {Measuring sample quality with kernels},
   booktitle = {International Conference on Machine Learning},
   publisher = {PMLR},
   pages = {1292-1301},
   ISBN = {2640-3498},
   type = {Conference Proceedings}
}

@article{Sana,
	author = {Xie, Enze and Chen, Junsong and Chen, Junyu and Cai, Han and Tang, Haotian and Lin, Yujun and Zhang, Zhekai and Li, Muyang and Zhu, Ligeng and Lu, Yao},
	title = {Sana: Efficient high-resolution image synthesis with linear diffusion transformers},
	journal = {arXiv preprint arXiv:2410.10629},
	year = {2024},
	type = {Journal Article}
}



@article{Anderson,
   author = {Anderson, Brian DO},
   title = {Reverse-time diffusion equation models},
   journal = {Stochastic Processes and their Applications},
   volume = {12},
   number = {3},
   pages = {313-326},
   ISSN = {0304-4149},
   year = {1982},
   type = {Journal Article}
}

@article{ODESolver1,
   author = {Karras, Tero and Aittala, Miika and Aila, Timo and Laine, Samuli},
   title = {Elucidating the design space of diffusion-based generative models},
   journal = {Advances in neural information processing systems},
   volume = {35},
   pages = {26565-26577},
   year = {2022},
   type = {Journal Article}
}

@article{ODESolver2,
   author = {Lu, Cheng and Zhou, Yuhao and Bao, Fan and Chen, Jianfei and Li, Chongxuan and Zhu, Jun},
   title = {Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps},
   journal = {Advances in Neural Information Processing Systems},
   volume = {35},
   pages = {5775-5787},
   year = {2022},
   type = {Journal Article}
}
@article{ODESolver3,
   author = {Zhang, Qinsheng and Chen, Yongxin},
   title = {Fast sampling of diffusion models with exponential integrator},
   journal = {arXiv preprint arXiv:2204.13902},
   year = {2022},
   type = {Journal Article}
}

@article{FastSDE,
   author = {Jolicoeur-Martineau, Alexia and Li, Ke and Piché-Taillefer, Rémi and Kachman, Tal and Mitliagkas, Ioannis},
   title = {Gotta go fast when generating data with score-based models},
   journal = {arXiv preprint arXiv:2105.14080},
   year = {2021},
   type = {Journal Article}
}


@article{MCMC,
   author = {Tierney, Luke},
   title = {Markov chains for exploring posterior distributions},
   journal = {the Annals of Statistics},
   pages = {1701-1728},
   ISSN = {0090-5364},
   year = {1994},
   type = {Journal Article}
}

@article{VariationalInference,
	author = {Blei, David M and Kucukelbir, Alp and McAuliffe, Jon D},
	title = {Variational inference: A review for statisticians},
	journal = {Journal of the American statistical Association},
	volume = {112},
	number = {518},
	pages = {859-877},
	ISSN = {0162-1459},
	year = {2017},
	type = {Journal Article}
}


