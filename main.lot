\babel@toc {english}{}\relax 
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {table}{\numberline {4.1}{\ignorespaces Number of parameters for the individual components of the Transformer block and the total Pixart-$\Sigma $ model.}}{32}{table.4.1}%
\contentsline {table}{\numberline {4.2}{\ignorespaces Number of parameters for the individual components of double-stream block from Flux-dev.}}{37}{table.4.2}%
\contentsline {table}{\numberline {4.3}{\ignorespaces Inference Parameters}}{41}{table.4.3}%
\contentsline {table}{\numberline {4.4}{\ignorespaces Inference Parameters}}{41}{table.4.4}%
\addvspace {10\p@ }
\contentsline {table}{\numberline {5.1}{\ignorespaces Default hyperparameters for the retraining of compressed models.}}{50}{table.5.1}%
\contentsline {table}{\numberline {5.2}{\ignorespaces Training hyperparameters for PixArt \gls {LoRA} finetuning and mask learning}}{59}{table.5.2}%
\contentsline {table}{\numberline {5.3}{\ignorespaces Training and Model Specifications for Compressed Variants.}}{60}{table.5.3}%
\contentsline {table}{\numberline {5.4}{\ignorespaces Comparing training steps and modified blocks for block removal versus \gls {SVD} compression method.}}{63}{table.5.4}%
\contentsline {table}{\numberline {5.5}{\ignorespaces \textbf {Flux Training and Compression Hyperparameters.} Configuration details for the compressed model fine-tuning run, including optimizer settings and Flow Matching specific parameters. This parameters represent my config setup for the training using the git repository \cite {kohya_ss_sd_scripts_2024}.}}{68}{table.5.5}%
\addvspace {10\p@ }
