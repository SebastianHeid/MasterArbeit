\pagenumbering{arabic}
\chapter{Introduction}
Over the past few years, generative artificial intelligence (\gls{AI})  has gained immense importance and relevance in society, as well as in business and politics. In addition to large language models (\gls{LLM}s) \cite{Claude,GPT4,Gemini,Lama}, which have brought generative AI into the mainstream, generative image models \cite{Flux,Pixart_s,baldridge2024imagen,brooks2024video,SD21,SDXL} are increasingly coming into focus. On the one hand, they open up a range of new possibilities in areas such as design and marketing as well as gaming and entertainment. On the other hand, they enable the generation of highly realistic synthetic images and videos, often referred to as deepfakes, raising severe ethical and privacy concerns, which is why policymakers are striving to establish rule-based guidelines for their use (European AI Act). \\
The advent of deep learning based image generators is often marked by the introduction of variational autoencoders (\gls{VAE}s) in 2013 \cite{VAE}, as they demonstrated that neural networks could learn complex data distribution and generate novel samples. Subsequently, generative adversarial networks (\gls{GAN}s) \cite{GAN,StyleGAN_3,StyleGAN_T} became the dominant model type in the image generation field as they produce images of significantly higher quality than \gls{VAE}s. However, \gls{GAN}s are notoriously difficult to train, as they often exhibit mode collapse and suffer from exploding or vanishing gradients \cite{ModeCollapse1,ImprovedGANTraining, PacGAN}.\\
 In recent years, \gls{GAN}s were largely surpassed by diffusion models \cite{DDPM} deploying an iterative image generation denoising process. The breakthrough of diffusion models as the new state-of-the-art (\gls{SOTA}) in image generation occured mainly in 2022 when the latent diffusion models, most notably Stable Diffusion \cite{LDM}, were released. At this time, they excelled in image quality and image generation diversity, but came with the cost of high inference time due to the iterative nature of their image generation process. The transition from pixel space to latent space massively reduced the computing time of the models and enabled images with higher resolution to be generated.\\
  The first stable diffusion models \cite{SD21,SDXL} leveraged a U-Net architecture \cite{Unet} and already required a huge amount of training data and computational resources. Their image generation process is typically controlled by textual prompts provided via cross-attention mechanisms \cite{AttentionIsAllYouNeed}. To expand these capabilities, several new control and finetuning methods like ControlNet \cite{ControlNet} and DreamBooth \cite{ruiz2023dreamboothfinetuningtexttoimage} were developed to enable precise spatial conditioning and personalization. Since the U-Net-based SD models already included transformer layers \cite{AttentionIsAllYouNeed} for text-conditioning, the next logical evolution was to transition to purely transformer-based models known as diffusion transformers (\gls{DiT}s) \cite{DiT}, which increased significantly in parameter size and required even more training data. In addition, a new formulation, so-called flow-matching, became predominant due to improved training stability and sampling efficiency which is leveraged by the current SOTA image generation models like Flux.1-dev \cite{Flux} being a 11.9 billion parameter model.\\
  Possible areas of application for diffusion and flow models include edge devices such as mobile phones \cite{li2023snapfusion,chen2023speed,zhao2024mobilediffusion}. In these cases, it is advantageous to run these models directly on the edge devices in order to avoid server costs, to make the associated functionality available offline, and to protect the privacy of users so that, for example, images do not have to be uploaded to external servers for processing.
  However, the current flow-based models like Flux.1-dev face two distinct challenges for real-time applications on edge devices. On the one hand, as mentioned before, they suffer from a long inference time due to the sequential application of the model. On the other hand, these models also require a substantial amount of VRAM during inference, e.g. Flux.1-dev requires about 32GB, which makes them unsuitable on edge devices.\\
Reducing VRAM and faster execution plays also a pivotal role in democratising these models and making them more environmentally friendly, as they can run on consumer-grade hardware and do not require power-intensive data centres reducing carbon footprint.\\
  The main research stream for speeding up the inference time is to enable the model to generate high-quality images with fewer inference steps. While at the beginning, diffusion models required up to 1000 inference steps to generate one single image, using more advanced \gls{ODE}-solvers for the denoising trajectory has led to significant reduction in inference steps.\\ Another line of research is step- and guidance distillation. Distillation methods generally attempt to transfer the capabilities of a teacher model to a student model. In step distillation, the same diffusion model is often used as both the teacher and student model, and the goal is to teach the student model to generate images of the same or similar quality with as few as four or two, sometimes even only a single inference step leveraging its original capabilities \cite{ADD,LADD,ProgressiveDistillation,ConsistencyModel,LatentConsistencyModel,DistillationMatching}. This technique is for example applied to Flux.1-dev resulting in Flux.1-schnell, reducing the required inference steps to only four.\\
   In guidance distillation, the goal is to incorporate the concept of classifier free guidance (\gls{CFG}), which normally requires the model to be applied twice per inference step, into the model itself, thereby saving half of the model evaluations \cite{GuidedDistillation}. This procedure was utilized to distill Flux.1-pro into Flux.1-dev.\\
  However, while step distillation and advanced solver effectively reduce the latency (inference time), they do not necessiarily adress the second bottleneck, namely high \gls{VRAM} consumption. Proposed methods for \gls{VRAM} reduction range from quantization \cite{han2015deep,FluxBit} and more efficient implementation of model components, e.g. Flash Attention \cite{FlashAttention}, to structural or unstructural model pruning \cite{Bksdm,Laptop,Koala,FastFlux,flux1-lite,flux_mini_2024,EcoDiff,PPCL,HierarchicalPrune}. While quantization compresses the model size by reducing the precision of the model parameters, pruning directly addresses the phenomenon that modern models, which have a high number of parameters, exhibit high redundancy in and between the individual transformer blocks. For this reason, identification followed by compression of redundant model parts is a promising orthogonal approach to reducing inference steps for further efficiency gains.\\
   The first part of this Master's thesis systematically examines how the number of parameters in diffusion transformers can be effectively reduced while minimizing the degradation of image generation quality, using PixArt-$\Sigma$ \cite{Pixart_s} as a representative baseline enabling the execution of numerous experiments due to its significantly smaller parameter count compared to Flux.1-dev.
   Specifically, the identification of architectural components with redundant parameters alongside the best pruning strategies, e.g., complete layer removal versus low-rank compression, and pruning schedules, e.g., one-shot versus progressive pruning are investigated. 
   Furthermore, various post-compression retraining frameworks are evaluated to optimize performance recovery. The empirical results demonstrate that progressively compressing model blocks via low-rank approximation using a linear distribution of compression ratios over transformer blocks meaning compressing the least important structures most aggressively and more critical structures less, leads to the best results. \\
   In the second part of this Master's thesis, the previously identified best pruning strategy is applied to the Flux.1-dev model and compared with other existing compression methods.\\
    Furthermore, a training-free compression strategy originally proposed for \gls{LLM}s \gls{GRASP} that is also based on singular value decomposition (\gls{SVD}) is transferred to Flux.1-dev and tested in comparison with current alternative approach \cite{EcoDiff}. \\
  
The remainder of this Master's thesis is structured as follows: Chapter two provides a comprehensive overview of image generator models, emphasizing diffusion and flow models, alongside relevant metrics used for measuring the performance. Building up on this context, chapter three contextualizes this work within the current literature by reviewing alternative model compression techniques. With the background established, chapter four introduces the specific methodologies investigated in this work. Their effectiveness is then rigorously evaluated through experimental results in chapter five. Finally, chapter six concludes the thesis with a comprehensive discussion of the main findings and their implications.
  
  
  

%   Famous distillation frameworks are latent adversarial diffusion distillation \cite{ADD,LADD} which utilizes besides a teacher model a discriminator as additional learning signal which differentiate if an image was generated by the student model or is from the real dataset or latent consistency models \cite{ConsistencyModel,LatentConsistencyModel} which are designed to map images with different noise levels to their corresponding clean image in one step by enforcing the self-consistency property meaning that two noisy images lying on the same denoising path are always mapped to the same clean image.
