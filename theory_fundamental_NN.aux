\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{AttentionIsAllYouNeed}
\citation{Claude,Gemini,Flux,HiDream}
\citation{RNN}
\citation{GPT4,Lama}
\citation{BERT}
\citation{ResidualConnection}
\citation{LayerNorm}
\citation{AttentionIsAllYouNeed}
\citation{AttentionIsAllYouNeed}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Fundamentals of Neural Network Architectures}{19}{section.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Transformer}{19}{subsection.1.3.1}\protected@file@percent }
\citation{OrgAttention}
\citation{OrgAttention}
\citation{AttentionIsAllYouNeed}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Transformer architecture from \cite  {AttentionIsAllYouNeed}.}}{20}{figure.1.5}\protected@file@percent }
\newlabel{transformer_architecture}{{1.5}{20}{Transformer architecture from \cite {AttentionIsAllYouNeed}}{figure.1.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}Attention Mechanism}{20}{subsection.1.3.2}\protected@file@percent }
\citation{Performer,Reformer,SparseTransformer,FlashAttention}
\citation{SelfAttentionFigure}
\citation{SelfAttentionFigure}
\@writefile{toc}{\contentsline {subsubsection}{Self-Attention}{21}{section*.18}\protected@file@percent }
\citation{SelfAttentionFigure}
\citation{SelfAttentionFigure}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces Self-attention mechanism inspired from \cite  {SelfAttentionFigure}.}}{22}{figure.1.6}\protected@file@percent }
\newlabel{SelfAttentionFigure}{{1.6}{22}{Self-attention mechanism inspired from \cite {SelfAttentionFigure}}{figure.1.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{Cross-Attention}{22}{section*.19}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces Cross-attention mechanism inspired from \cite  {SelfAttentionFigure}.}}{22}{figure.1.7}\protected@file@percent }
\newlabel{CrossAttentionFigure}{{1.7}{22}{Cross-attention mechanism inspired from \cite {SelfAttentionFigure}}{figure.1.7}{}}
\citation{AttentionIsAllYouNeed}
\citation{AttentionIsAllYouNeed}
\citation{RoPE,ALiBi,FIRE}
\citation{AttentionIsAllYouNeed,Floater,Cape,Shape}
\citation{AttentionIsAllYouNeed,Shape,Cape,ALiBi,RoPE}
\citation{Floater,FIRE}
\citation{AttentionIsAllYouNeed}
\@writefile{toc}{\contentsline {subsubsection}{Multi-Head Attention}{23}{section*.20}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces Multi-head attention from \cite  {AttentionIsAllYouNeed}.}}{23}{figure.1.8}\protected@file@percent }
\newlabel{MultiHeadAttention}{{1.8}{23}{Multi-head attention from \cite {AttentionIsAllYouNeed}}{figure.1.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.3}Positional Encoding}{23}{subsection.1.3.3}\protected@file@percent }
\citation{PositionalEmbeddingSurvey}
\citation{RoPE}
\citation{Flux}
\@writefile{toc}{\contentsline {subsubsection}{Sinusoidal Positional Encoding}{24}{section*.21}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Rotary Position Embedding}{24}{section*.22}\protected@file@percent }
\citation{RoPE}
\citation{RoPE}
\citation{StandAloneAttentionVisonModels,Ccnet,ImageTransformer}
\citation{CNN}
\@writefile{lof}{\contentsline {figure}{\numberline {1.9}{\ignorespaces Scheme of implementation of rotational position encoding from \cite  {RoPE}.}}{25}{figure.1.9}\protected@file@percent }
\newlabel{RoPE_fig}{{1.9}{25}{Scheme of implementation of rotational position encoding from \cite {RoPE}}{figure.1.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.4}Vision Transformer}{25}{subsection.1.3.4}\protected@file@percent }
\citation{VisionTransformer}
\citation{VisionTransformer}
\citation{VisionTransformer}
\@writefile{lof}{\contentsline {figure}{\numberline {1.10}{\ignorespaces Vision transformer from \cite  {VisionTransformer}.}}{26}{figure.1.10}\protected@file@percent }
\newlabel{VisionTransformer}{{1.10}{26}{Vision transformer from \cite {VisionTransformer}}{figure.1.10}{}}
\@setckpt{theory_fundamental_NN}{
\setcounter{page}{27}
\setcounter{equation}{87}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{1}
\setcounter{section}{3}
\setcounter{subsection}{4}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{10}
\setcounter{table}{0}
\setcounter{parentequation}{0}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{float@type}{8}
\setcounter{NAT@ctr}{0}
\setcounter{section@level}{2}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{16}
\setcounter{algorithm}{3}
\setcounter{ALG@line}{8}
\setcounter{ALG@rem}{8}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
}
