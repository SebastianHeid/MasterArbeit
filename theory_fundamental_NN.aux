\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{AttentionIsAllYouNeed}
\citation{Claude,Gemini,Flux,HiDream}
\citation{RNN}
\citation{GPT4,Lama}
\citation{BERT}
\citation{ResidualConnection}
\citation{LayerNorm}
\citation{AttentionIsAllYouNeed}
\citation{AttentionIsAllYouNeed}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Fundamentals of Neural Network Architectures}{17}{section.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.1}Transformer}{17}{subsection.1.3.1}\protected@file@percent }
\citation{OrgAttention}
\citation{OrgAttention}
\citation{AttentionIsAllYouNeed}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces Transformer architecture from \cite  {AttentionIsAllYouNeed}.}}{18}{figure.1.5}\protected@file@percent }
\newlabel{transformer_architecture}{{1.5}{18}{Transformer architecture from \cite {AttentionIsAllYouNeed}}{figure.1.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.2}Attention Mechanism}{18}{subsection.1.3.2}\protected@file@percent }
\citation{Performer,Reformer,SparseTransformer,FlashAttention}
\citation{SelfAttentionFigure}
\citation{SelfAttentionFigure}
\@writefile{toc}{\contentsline {subsubsection}{Self-Attention}{19}{section*.16}\protected@file@percent }
\citation{SelfAttentionFigure}
\citation{SelfAttentionFigure}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces Self-attention mechanism inspired from \cite  {SelfAttentionFigure}.}}{20}{figure.1.6}\protected@file@percent }
\newlabel{SelfAttentionFigure}{{1.6}{20}{Self-attention mechanism inspired from \cite {SelfAttentionFigure}}{figure.1.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{Cross-Attention}{20}{section*.17}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces Cross-attention mechanism inspired from \cite  {SelfAttentionFigure}.}}{20}{figure.1.7}\protected@file@percent }
\newlabel{CrossAttentionFigure}{{1.7}{20}{Cross-attention mechanism inspired from \cite {SelfAttentionFigure}}{figure.1.7}{}}
\citation{AttentionIsAllYouNeed}
\citation{AttentionIsAllYouNeed}
\citation{RoPE,ALiBi,FIRE}
\citation{AttentionIsAllYouNeed,Floater,Cape,Shape}
\citation{AttentionIsAllYouNeed,Shape,Cape,ALiBi,RoPE}
\citation{Floater,FIRE}
\citation{AttentionIsAllYouNeed}
\@writefile{toc}{\contentsline {subsubsection}{Multi-Head Attention}{21}{section*.18}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces Multi-head attention from \cite  {AttentionIsAllYouNeed}.}}{21}{figure.1.8}\protected@file@percent }
\newlabel{MultiHeadAttention}{{1.8}{21}{Multi-head attention from \cite {AttentionIsAllYouNeed}}{figure.1.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.3}Positional Encoding}{21}{subsection.1.3.3}\protected@file@percent }
\citation{PositionalEmbeddingSurvey}
\citation{RoPE}
\citation{Flux}
\@writefile{toc}{\contentsline {subsubsection}{Sinusoidal Positional Encoding}{22}{section*.19}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Rotary Position Embedding}{22}{section*.20}\protected@file@percent }
\citation{RoPE}
\citation{RoPE}
\citation{StandAloneAttentionVisonModels,Ccnet,ImageTransformer}
\citation{CNN}
\@writefile{lof}{\contentsline {figure}{\numberline {1.9}{\ignorespaces Scheme of implementation of rotational position encoding from \cite  {RoPE}.}}{23}{figure.1.9}\protected@file@percent }
\newlabel{RoPE_fig}{{1.9}{23}{Scheme of implementation of rotational position encoding from \cite {RoPE}}{figure.1.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3.4}Vision Transformer}{23}{subsection.1.3.4}\protected@file@percent }
\citation{VisionTransformer}
\citation{VisionTransformer}
\citation{VisionTransformer}
\@writefile{lof}{\contentsline {figure}{\numberline {1.10}{\ignorespaces Vision transformer from \cite  {VisionTransformer}.}}{24}{figure.1.10}\protected@file@percent }
\newlabel{VisionTransformer}{{1.10}{24}{Vision transformer from \cite {VisionTransformer}}{figure.1.10}{}}
\@setckpt{theory_fundamental_NN}{
\setcounter{page}{25}
\setcounter{equation}{87}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{1}
\setcounter{section}{3}
\setcounter{subsection}{4}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{10}
\setcounter{table}{0}
\setcounter{parentequation}{0}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{float@type}{8}
\setcounter{NAT@ctr}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{section@level}{2}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{16}
\setcounter{algorithm}{3}
\setcounter{ALG@line}{8}
\setcounter{ALG@rem}{8}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
}
