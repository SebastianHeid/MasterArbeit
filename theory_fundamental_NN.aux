\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{AttentionIsAllYouNeed}
\citation{Claude,Gemini,Flux,HiDream}
\citation{RNN}
\citation{GPT4,Lama}
\citation{BERT}
\citation{ResidualConnection}
\citation{LayerNorm}
\citation{AttentionIsAllYouNeed}
\citation{AttentionIsAllYouNeed}
\citation{OrgAttention}
\citation{OrgAttention}
\citation{AttentionIsAllYouNeed}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Fundamentals of Neural Network Architectures}{18}{section.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Transformer}{18}{subsection.2.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Transformer Architecture}}{18}{figure.2.6}\protected@file@percent }
\newlabel{transformer_architecture}{{2.6}{18}{Transformer Architecture}{figure.2.6}{}}
\citation{Performer,Reformer,SparseTransformer,FlashAttention}
\citation{SelfAttentionFigure}
\citation{SelfAttentionFigure}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Attention Mechanism}{19}{subsection.2.3.2}\protected@file@percent }
\newlabel{AttentionMechanism}{{2.3.2}{19}{Attention Mechanism}{subsection.2.3.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{Self-Attention}{19}{section*.14}\protected@file@percent }
\newlabel{AttentionEq}{{2.82}{19}{Self-Attention}{equation.2.82}{}}
\citation{SelfAttentionFigure}
\citation{SelfAttentionFigure}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Self-Attention Mechanism}}{20}{figure.2.7}\protected@file@percent }
\newlabel{SelfAttentionFigure}{{2.7}{20}{Self-Attention Mechanism}{figure.2.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{Cross-Attention}{20}{section*.15}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Cross-Attention Mechanism}}{20}{figure.2.8}\protected@file@percent }
\newlabel{CrossAttentionFigure}{{2.8}{20}{Cross-Attention Mechanism}{figure.2.8}{}}
\citation{AttentionIsAllYouNeed}
\citation{AttentionIsAllYouNeed}
\citation{RoPE,ALiBi,FIRE}
\citation{AttentionIsAllYouNeed,Floater,Cape,Shape}
\citation{AttentionIsAllYouNeed,Shape,Cape,ALiBi,RoPE}
\citation{Floater,FIRE}
\citation{AttentionIsAllYouNeed}
\@writefile{toc}{\contentsline {subsubsection}{Multi-Head Attention}{21}{section*.16}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Multi-Head Attention}}{21}{figure.2.9}\protected@file@percent }
\newlabel{MultiHeadAttention}{{2.9}{21}{Multi-Head Attention}{figure.2.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Positional Encoding}{21}{subsection.2.3.3}\protected@file@percent }
\newlabel{PositionalEmbedding}{{2.3.3}{21}{Positional Encoding}{subsection.2.3.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{Sinusoidal Positional Encoding}{21}{section*.17}\protected@file@percent }
\citation{StandAloneAttentionVisonModels,Ccnet,ImageTransformer}
\citation{CNN}
\citation{VisionTransformer}
\citation{VisionTransformer}
\citation{VisionTransformer}
\citation{LayerNorm}
\citation{BatchNorm}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}Vision Transformer}{22}{subsection.2.3.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Vision Transformer Architecture}}{22}{figure.2.10}\protected@file@percent }
\newlabel{VisionTransformer}{{2.10}{22}{Vision Transformer Architecture}{figure.2.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.5}Adaptive Layer Normalization}{22}{subsection.2.3.5}\protected@file@percent }
\newlabel{AdaptiveLayerNormalization}{{2.3.5}{22}{Adaptive Layer Normalization}{subsection.2.3.5}{}}
\citation{adaLN}
\citation{DiT}
\@setckpt{theory_fundamental_NN}{
\setcounter{page}{24}
\setcounter{equation}{87}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{3}
\setcounter{subsection}{5}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{10}
\setcounter{table}{0}
\setcounter{parentequation}{0}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{float@type}{8}
\setcounter{NAT@ctr}{0}
\setcounter{section@level}{2}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{24}
\setcounter{algorithm}{3}
\setcounter{ALG@line}{8}
\setcounter{ALG@rem}{8}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
}
