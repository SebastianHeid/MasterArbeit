\babel@toc {english}{}\relax 
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces The graphical model of DDPM from \cite {DDPM}.}}{6}{figure.2.1}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces DDPM training \cite {DDPMSamplerImage}.}}{10}{figure.2.2}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces DDPM sampling \cite {DDPMSamplerImage}.}}{11}{figure.2.3}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces Rectified Flow \cite {RectifiedFlowMatching}.}}{15}{figure.2.4}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces Structure of a Latent Diffusion Model \cite {LDM}.}}{16}{figure.2.5}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces Transformer architecture from \cite {AttentionIsAllYouNeed}.}}{17}{figure.2.6}%
\contentsline {figure}{\numberline {2.7}{\ignorespaces Self-attention mechanism based on \cite {SelfAttentionFigure}.}}{19}{figure.2.7}%
\contentsline {figure}{\numberline {2.8}{\ignorespaces Cross-attention mechanism based on \cite {SelfAttentionFigure}.}}{19}{figure.2.8}%
\contentsline {figure}{\numberline {2.9}{\ignorespaces Multi-head attention from \cite {AttentionIsAllYouNeed}.}}{20}{figure.2.9}%
\contentsline {figure}{\numberline {2.10}{\ignorespaces Vision transformer from \cite {VisionTransformer}.}}{21}{figure.2.10}%
\contentsline {figure}{\numberline {2.11}{\ignorespaces Example of how image is investigated for GenEval benchmark \cite {ghosh2023geneval}.}}{27}{figure.2.11}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Overview architecture of Pixart-$\Sigma $. $H$ and $W$ are the height and width of the image. $h=\frac {H}{8}$ and $w=\frac {W}{8}$ represent the dimensions in latent space and $N = \frac {H}{8 \cdot p} \frac {W}{8 \cdot p}$ with $p$ being the patch size.}}{31}{figure.4.1}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces Diffusion block architecture taken from \cite {Pixart_a}.}}{32}{figure.4.2}%
\contentsline {figure}{\numberline {4.3}{\ignorespaces Overview Flux-dev architecture.}}{35}{figure.4.3}%
\contentsline {figure}{\numberline {4.4}{\ignorespaces Single-stream block (left) and double-stream block (right) of Flux-dev. Graphics are adapted from \cite {FastFlux}.}}{36}{figure.4.4}%
\contentsline {figure}{\numberline {4.5}{\ignorespaces Example of LAION Dataset}}{40}{figure.4.5}%
\contentsline {figure}{\numberline {4.6}{\ignorespaces PixArt-$\Sigma $ generated dataset}}{41}{figure.4.6}%
\contentsline {figure}{\numberline {4.7}{\ignorespaces Flux-dev generated dataset}}{41}{figure.4.7}%
\contentsline {figure}{\numberline {4.8}{\ignorespaces Examples of Mapillary Dataset}}{42}{figure.4.8}%
\contentsline {figure}{\numberline {4.9}{\ignorespaces Examples of Cityscapes Dataset}}{42}{figure.4.9}%
\contentsline {figure}{\numberline {4.10}{\ignorespaces Examples of MHJQ-30k Dataset}}{43}{figure.4.10}%
\contentsline {figure}{\numberline {4.11}{\ignorespaces Example of removal (left) and compression (right) strategy based on a simplified representation of PixArt-$\Sigma $ architecture. The depictions show the case that the blocks 8,11,15,17 and 20 are removed or compressed. }}{44}{figure.4.11}%
\contentsline {figure}{\numberline {4.12}{\ignorespaces }}{46}{figure.4.12}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces Qualitative analyse of the block sensitivity of PixArt-$\Sigma $ for block removal}}{51}{figure.5.1}%
\contentsline {figure}{\numberline {5.2}{\ignorespaces Magnitude-base pruning vs \gls {CLIP}-score}}{52}{figure.5.2}%
\contentsline {figure}{\numberline {5.3}{\ignorespaces Magnitude-base pruning vs \gls {CMMD}}}{52}{figure.5.3}%
\contentsline {figure}{\numberline {5.4}{\ignorespaces \gls {CKA} transformation intensity vs \gls {CLIP}-score}}{53}{figure.5.4}%
\contentsline {figure}{\numberline {5.5}{\ignorespaces \gls {CKA} transformation intensity vs \gls {CMMD}}}{53}{figure.5.5}%
\contentsline {figure}{\numberline {5.6}{\ignorespaces Qualitative analyse of the block sensitivity of PixArt-$\Sigma $ of block compression}}{55}{figure.5.6}%
\contentsline {figure}{\numberline {5.7}{\ignorespaces Comparison of Pruning Strategies: Optuna vs. Greedy Algorithm}}{56}{figure.5.7}%
\contentsline {figure}{\numberline {5.8}{\ignorespaces Comparison of Pruning Strategies}}{57}{figure.5.8}%
\contentsline {figure}{\numberline {5.9}{\ignorespaces Comparison of Pruning Strategies: Optuna vs. Greedy Algorithm Regarding Training}}{57}{figure.5.9}%
\contentsline {figure}{\numberline {5.10}{\ignorespaces Comparison of Pruning Strategies}}{58}{figure.5.10}%
\contentsline {figure}{\numberline {5.11}{\ignorespaces Investigation of Knowledge Distialltion Loss}}{60}{figure.5.11}%
\contentsline {figure}{\numberline {5.12}{\ignorespaces Magnitude of Intermediate Features in PixArt-$\Sigma $}}{60}{figure.5.12}%
\contentsline {figure}{\numberline {5.13}{\ignorespaces Finetuning Protocols Benchmark}}{61}{figure.5.13}%
\contentsline {figure}{\numberline {5.14}{\ignorespaces Benchmarks Structural Compression Strategy}}{62}{figure.5.14}%
\contentsline {figure}{\numberline {5.15}{\ignorespaces Benchmarks Structural Compression Strategy}}{63}{figure.5.15}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {6.2}{\ignorespaces Comparison of removed blocks for one-shot vs progressive model pruning for different compression stages (90\% to 50\%).}}{65}{figure.6.2}%
